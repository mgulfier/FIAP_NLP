{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem.rslp import RSLPStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from copy import deepcopy\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24730.960917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14277.792868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12366.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37095.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49460.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id\n",
       "count  49459.000000\n",
       "mean   24730.960917\n",
       "std    14277.792868\n",
       "min        1.000000\n",
       "25%    12366.500000\n",
       "50%    24731.000000\n",
       "75%    37095.500000\n",
       "max    49460.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carrega o dataset a partir de uma url da aws\n",
    "df_original = pd.read_csv('https://s3.amazonaws.com/aulas-fiap/imdb-reviews-pt-br.csv')\n",
    "\n",
    "#Exibe as características do dataset\n",
    "df_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            text_en  \\\n",
       "0   1  Once again Mr. Costner has dragged out a movie...   \n",
       "1   2  This is an example of why the majority of acti...   \n",
       "2   3  First of all I hate those moronic rappers, who...   \n",
       "3   4  Not even the Beatles could write songs everyon...   \n",
       "4   5  Brass pictures movies is not a fitting word fo...   \n",
       "\n",
       "                                             text_pt sentiment  \n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
       "4  Filmes de fotos de latão não é uma palavra apr...       neg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atribui o dataset que será trabalhado \n",
    "df = df_original \n",
    "\n",
    "#converte todas as palavras para minúsculo porque considero que não há diferença entre maiúsculas e minúsculas \n",
    "#para capturar o sentimento contido nas frases\n",
    "df.text_pt = df.text_pt.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vetoriza o texto utilizando TF-IDF em unigramas \n",
    "vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
    "vect.fit(df.text_pt)\n",
    "text_vect = vect.transform(df.text_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treina com a proporção de 80% para treinamento e 20% para teste\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    text_vect, \n",
    "    df.sentiment,\n",
    "    test_size = 0.2, \n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de treinamento: 80.64453482627869s\n",
      "F1 Score: 0.7077\n"
     ]
    }
   ],
   "source": [
    "#Testa com Árvore de Decisão\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42) \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = tree.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gera um indicador F1 levemente acima do mínimo pedido pelo professor. Mínimo pedido = 70%. Obtido = <b>70,77 %</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de treinamento: 0.07299971580505371s\n",
      "F1 Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "#Testa com KNN\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "neigh.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = neigh.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtido agora um F1 Score de <b>78%</b>. Melhor que árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com SVM SVC\n",
    "\n",
    "svm_clf = SVC(C=100, kernel='linear',random_state =42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = svm_clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda melhor, o modelo SVM SVC obteve um F1 Score de <b>87,37%</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com SVM Linear\n",
    "\n",
    "svm_linear = LinearSVC(penalty='l1',dual=False,C=1.0, random_state =42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = svm_linear.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor até então, o SVM Linear conseguiu <b>88,89%</b> de F1 Score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com Random forest\n",
    "\n",
    "rand_forest = RandomForestClassifier(n_estimators=300,random_state=42,max_depth=30)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "rand_forest.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = rand_forest.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Random Forest não teve um desempenho tão bom, ficou abaixo dos algoritmos de SVM. F1 Score de <b>84,41%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Teste com Naive Bayes - Bernoulli ####\n",
    "\n",
    "naive_berno = BernoulliNB()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "naive_berno.fit(X_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = naive_berno.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo da Linha de Naive Bayes (probabilístico) é bem simples e ainda assim conseguiu um desempenho muito bom. \n",
    "F1 Score obtido é de <b>85,70%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Teste com outro algoritmo probabilístico da família Naive Bayes - Multinomial ###\n",
    "\n",
    "naive_multi = MultinomialNB()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "naive_multi.fit(X_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = naive_multi.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como o outro algoritmo da mesma família, apresenta um bom desempenho e obtem um F1 score ligeiramente superior <b>86,17%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste com o XGBBoost - XGBClassifier #\n",
    "\n",
    "def xgb_f1(y,t):\n",
    "    t = t.get_label()\n",
    "    y_bin = [1. if y_cont > 0.5 else 0. for y_cont in y] # arredondamento para converter para 0. ou 1.\n",
    "    return 'f1',f1_score(t,y_bin,average='weighted')\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=15, learning_rate=0.004,\n",
    "                            n_estimators=200,\n",
    "                            booster='gbtree',\n",
    "                            silent=True,   objective='binary:logistic',\n",
    "                            nthread=-1, gamma=0,\n",
    "                            min_child_weight=1, max_delta_step=0, subsample=0.8,\n",
    "                            colsample_bytree=0.6,\n",
    "                            base_score=0.5,\n",
    "                            seed=0, missing=None)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "xgb_clf.fit(X_train, y_train, eval_metric=xgb_f1,\n",
    "         eval_set=[(X_train, y_train)],\n",
    "         early_stopping_rounds=900)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_pred, y_test, average='weighted')\n",
    "\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo XGBClassifier não apresentou um bom desempenho. Apresentou o F1 Score final de apenas <b>71,55%</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deste modo, os próximos testes seguirão com os 3 melhores algoritmos considerando o F1 Score:\n",
    "<b>\n",
    "   - SVM Linear:    88,88%\n",
    "   - SVM SVC:       87,37%\n",
    "   - MultinomialNB: 86,16% \n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Próximo teste: Retirar stop words\n",
    "\n",
    "A próxima estratégia será a retirada de stop words do português utilizando spacy e a execução dos 3 melhores algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tirando stop words utilizando o spacy \n",
    "# Gerando novamente os vetores de teste  \n",
    "\n",
    "#Carrega base de português do spacy\n",
    "\n",
    "pt = spacy.load('pt_core_news_sm')\n",
    "\n",
    "nlp = spacy.load('pt')\n",
    "\n",
    "#Referência as stop words do spacy \n",
    "stop_words_spacy = nlp.Defaults.stop_words\n",
    "\n",
    "#Tokeniza com TF-IDF já excluindo as stop words \n",
    "vect_stop = TfidfVectorizer(ngram_range=(1,1), use_idf=True,stop_words=stop_words_spacy)\n",
    "vect_stop.fit(df.text_pt)\n",
    "text_vect_stop = vect_stop.transform(df.text_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz o novo split da nova amostra \n",
    "X_train_stop,X_test_stop,y_train_stop,y_test_stop = train_test_split(\n",
    "    text_vect_stop, \n",
    "    df.sentiment,\n",
    "    test_size = 0.2, \n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com SVM Linear mas com stop words já excluídas #\n",
    "\n",
    "svm_linear_stop = LinearSVC(penalty='l1',dual=False,C=1.0, random_state =42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_linear_stop.fit(X_train_stop, y_train_stop)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = svm_linear_stop.predict(X_test_stop)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stop, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O teste sem stop words gerou um F1 Score ligeiramente menor <b>88,16%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com SVM SVC mas com stop words já excluídas\n",
    "\n",
    "svm_clf_stop = SVC(C=100, kernel='linear',random_state =42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_clf_stop.fit(X_train_stop, y_train_stop)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = svm_clf_stop.predict(X_test_stop)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stop, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como no caso anterior, um resultado inferior ao apresentado com as stop words. F1 Score = <b>86,47%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa com multinomialNB mas com as stop words já excluídas\n",
    "\n",
    "naive_multi_stop = MultinomialNB()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "naive_multi_stop.fit(X_train_stop,y_train_stop)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = naive_multi_stop.predict(X_test_stop)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stop, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mesmo comportamento dos anteriores. Apresentou aqui um resultado inferior daquele com stop words. F1 Score = <b>86,11%</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "## Desse modo, a estratégia de excluir as stop words não se mostrou efetiva\n",
    "\n",
    "## A próxima estratégia será utilizar stemizadores e verificar os seus efeitos.\n",
    "\n",
    "## Como o algoritmo SVM SVC tem desempenho consistentemente inferior ao LinearSVC e demora em torno de 2 horas para ser executado, ele será excluído da lista de melhores algoritmos. \n",
    "\n",
    "## Seguiremos com os algoritmos: LinearSVC e MultinomialNB\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realiza o download dos stemizadores rslp e porter\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converte cada frase no Dataframe para a sua versão Stemizada pelo RSLPStemmer\n",
    "rslp = RSLPStemmer()\n",
    "\n",
    "#Função que converte o texto original para o stematizador RSLP\n",
    "def conv_stem(texto):\n",
    "  return ' '.join([rslp.stem(token) for token in texto.split(' ')])\n",
    "\n",
    "#Cria uma nova coluna no Dataframe com as frases stematizadas\n",
    "df['stemizado'] = df.text_pt.apply(conv_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokeniza as frases stemizadas\n",
    "\n",
    "#Vetoriza o texto utilizando TF-IDF em unigramas\n",
    "vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
    "vect.fit(df.stemizado)\n",
    "text_vect = vect.transform(df.stemizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treina com a proporção de 80% para treinamento e 20% para teste\n",
    "X_train_stem,X_test_stem,y_train_stem,y_test_stem = train_test_split(\n",
    "    text_vect, \n",
    "    df.sentiment,\n",
    "    test_size = 0.2, \n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com SVM Linear as frases lematizadas com RSLP\n",
    "\n",
    "svm_linear_stem = LinearSVC(penalty='l1',dual=False,C=1.0, random_state =42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_linear_stem.fit(X_train_stem, y_train_stem)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = svm_linear_stem.predict(X_test_stem)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stem, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado apresentado é inferior àquele com as stop words. O resultado não foi satisfatório. F1 Score atingido = <b>87,77%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa com multinomialNB\n",
    "naive_multi_stem = MultinomialNB()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "naive_multi_stem.fit(X_train_stem,y_train_stem)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = naive_multi_stem.predict(X_test_stem)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stem, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mesmo problema com o MultiNomialNB. Não foi satisfatório. F1 Score = <b>85,46%</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "## Repete os mesmos testes para o stemizador Porter\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria mais uma coluna no Dataframe com as frases stematizadas pelo outro stemizador Porter\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#Converte frases para o novo stemizador Porter\n",
    "def conv_stem(texto):\n",
    "  return ' '.join([ps.stem(token) for token in texto.split(' ')])\n",
    "\n",
    "#Carrega na nova coluna criada stemizado2\n",
    "df['stemizado2'] = df.text_pt.apply(conv_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vetoriza essa nova stemização\n",
    "\n",
    "#Vetoriza o texto utilizando TF-IDF em unigramas\n",
    "vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
    "vect.fit(df.stemizado2)\n",
    "text_vect = vect.transform(df.stemizado2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treina com a proporção de 80% para treinamento e 20% para teste\n",
    "X_train_stem2,X_test_stem2,y_train_stem2,y_test_stem2 = train_test_split(\n",
    "    text_vect, \n",
    "    df.sentiment,\n",
    "    test_size = 0.2, \n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com SVM Linear\n",
    "\n",
    "svm_linear_stem2 = LinearSVC(penalty='l1',dual=False,C=1.0, random_state =42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_linear_stem2.fit(X_train_stem2, y_train_stem2)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = svm_linear_stem2.predict(X_test_stem2)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stem2, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estratégia não foi bem sucedida. O F1 Score obtido não foi o suficiente. F1 Score obtido = <b>88,50%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa com multinomialNB\n",
    "\n",
    "naive_multi_stem2 = MultinomialNB()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "naive_multi_stem2.fit(X_train_stem2,y_train_stem2)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = naive_multi_stem2.predict(X_test_stem2)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_stem2, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mesmo comportamento. F1 Score inferior. Valor obtido = <b>85,83%</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Uma nova estratégia a ser testada é acrescentar informações sintáticas junto às palavras que compõem o texto. \n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acrescentando informação da análise sintática \n",
    "# Gerando novamente os vetores de teste  \n",
    "\n",
    "#Converte frase para o seguinte padrão <palavra original>-<classe sintática> \n",
    "def conv_sintatico(texto):\n",
    "    doc = pt(texto)\n",
    "    str = ''\n",
    "    for token in doc:\n",
    "        str += token.text + '-' + token.pos_ + ' '\n",
    "    return str \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#Cria uma nova coluna chamada sintatico com esse padrão\n",
    "df['sintatico'] = df.text_pt.apply(conv_sintatico)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de adição do POS Tagger: \" + str(end - start) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vetoriza os textos com a análise sintática\n",
    "\n",
    "#Vetoriza o texto utilizando TF-IDF em unigramas\n",
    "vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
    "vect.fit(df.sintatico)\n",
    "text_vect = vect.transform(df.sintatico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treina com a proporção de 80% para treinamento e 20% para teste\n",
    "X_train_sint,X_test_sint,y_train_sint,y_test_sint = train_test_split(\n",
    "    text_vect, \n",
    "    df.sentiment,\n",
    "    test_size = 0.2, \n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com SVM Linear\n",
    "\n",
    "svm_linear_sint = LinearSVC(penalty='l1',dual=False,C=1.0, random_state =42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_linear_sint.fit(X_train_sint, y_train_sint)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = svm_linear_sint.predict(X_test_sint)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_sint, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultados não foram suficientes. Ligeiramente menores. F1 Score = <b>88,85%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa com multinomialNB\n",
    "\n",
    "naive_multi_sint = MultinomialNB()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "naive_multi_sint.fit(X_train_sint,y_train_sint)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = naive_multi_sint.predict(X_test_sint)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_sint, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atribui o dataset que será trabalhado \n",
    "df = df_original \n",
    "\n",
    "#converte todas as palavras para minúsculo porque não há diferença entre maiúsculas e minúsculas \n",
    "#para capturar o sentimento contido nas frases\n",
    "df.text_pt = df.text_pt.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Outro teste realizado foi utilizar Word2Vec de 300 posições a partir de um base carregada da Internet ao invés do TF-IDF como método de vetorização\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz download da base a partir da Internet\n",
    "\n",
    "tar_gz_path = '../extras/cbow_s300.zip'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "  last_block = 0\n",
    "\n",
    "  def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "    self.total = total_size\n",
    "    self.update((block_num - self.last_block) * block_size)\n",
    "    self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "  with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Word2Vec Model') as pbar:\n",
    "    urlretrieve(\n",
    "      'http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s300.zip',\n",
    "      tar_gz_path,\n",
    "      pbar.hook)\n",
    "\n",
    "if not isfile('../extras/cbow_s300.txt'):     \n",
    "  zip_ref = zipfile.ZipFile(tar_gz_path, 'r')\n",
    "  zip_ref.extractall('../extras/')\n",
    "  zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tendo a base baixada, carrega para a memória\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model_cbow = KeyedVectors.load_word2vec_format('../extras/cbow_s300.txt')\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de carregamento: \" + str(end - start) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converte uma frase em um único vetor\n",
    "#Faz essa conversão pela soma dos vetores de cada palavras. \n",
    "#A soma será padronizada a partir da raiz quadrada da  média dos elementos ao quadrado\n",
    "\n",
    "def conv_word2vec_frase(frase):\n",
    "    soma =  np.zeros(model_cbow.vector_size)\n",
    "    rms = 0\n",
    "    \n",
    "        \n",
    "    for palavra in frase.split(' '):\n",
    "        palavra = palavra.translate(palavra.maketrans('', '', string.punctuation))    \n",
    "        try:\n",
    "            soma = soma + model_cbow[palavra]    \n",
    "        except:\n",
    "            soma = soma + 0\n",
    "        \n",
    "    rms = 0\n",
    "    \n",
    "    for i in range (model_cbow.vector_size):\n",
    "        rms = rms + (soma[i]*soma[i])\n",
    "            \n",
    "    rms = math.sqrt(rms / model_cbow.vector_size)\n",
    "        \n",
    "    word2vec_frase = soma / rms\n",
    "        \n",
    "            \n",
    "    return word2vec_frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma nova coluna na Dataframe para aplicar a conversão de frase em um vetor através do word2vec\n",
    "df['word2vec'] = df.text_pt.apply(conv_word2vec_frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converte o dataframe em uma matriz\n",
    "n_linhas = df.word2vec.values.shape[0]\n",
    "n_colunas = model_cbow.vector_size\n",
    "\n",
    "word2vec_matriz = np.empty((n_linhas,n_colunas))\n",
    "for i in range(n_linhas):\n",
    "    elemen = df.word2vec[i]\n",
    "    for j in range(n_colunas):\n",
    "        word2vec_matriz[i][j] = elemen[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz a divisão da matriz + classificação em amostra de treino e teste\n",
    "\n",
    "#Treina com a proporção de 80% para treinamento e 20% para teste\n",
    "X_train_cbow,X_test_cbow,y_train_cbow,y_test_cbow = train_test_split(\n",
    "    word2vec_matriz, \n",
    "    df.sentiment,\n",
    "    test_size = 0.2, \n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com SVM Linear sobre o dados convertidos via word2vec\n",
    "\n",
    "svm_linear_cbow = LinearSVC(penalty='l1',dual=False,C=1.0, random_state =42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_linear_cbow.fit(X_train_cbow, y_train_cbow)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = svm_linear_cbow.predict(X_test_cbow)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_cbow, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados foram ruins. Foi obtido apenas <b>79,61%</b> de F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa com multinomialNB\n",
    "# Como o algoritmo não permite vetores com números negativos\n",
    "# Realizo uma translação no vetor para ficar maior ou igual a zero\n",
    "\n",
    "#Faz translação antes de executar\n",
    "min_train = np.min(X_train_cbow) \n",
    "min_test = np.min(X_test_cbow)\n",
    "\n",
    "X_train_cbow2 = X_train_cbow - min_train\n",
    "X_test_cbow2 = X_test_cbow - min_test\n",
    "\n",
    "naive_multi_cbow = MultinomialNB()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "naive_multi_cbow.fit(X_train_cbow2,y_train_cbow)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = naive_multi_cbow.predict(X_test_cbow2)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_cbow, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado com o MultiNomialNB é muito pior, ficando abaixo do mínimo solicitado. Apenas <b>67,36%</b> de F1 Score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "## A estratégia agora será rodar uma rede neural (LSTM) em Keras para verificar se obtem melhor performance que as obtidas até então\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 1300\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(df.text_pt.values)\n",
    "X = tokenizer.texts_to_sequences(df.text_pt.values)\n",
    "#X = tokenizer.texts_to_matrix(df.text_pt.values,mode='tfidf')\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_keras(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "                 \n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "                 \n",
    "                 \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 777, 128)          166400    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 777, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 421,594\n",
      "Trainable params: 421,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = [f1_keras])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(df.sentiment).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/14\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = 14, batch_size=batch_size, verbose = 2)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,score_f1 = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"f1_score: %.4f\" % (score_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "## Mais uma estratégia, aumentar a quantidade de informações sobre os textos utilizando unigramas e bigramas nos modelos de classificação\n",
    "## Esse enriquecimento será feito nos textos originais (com stop words) que foi o que se mostrou mais promissor até então.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Teste com unigramas e bigramas e os 2 melhores algoritmos ####\n",
    "\n",
    "#Vetoriza o texto utilizando TFID em unigramas e digramas\n",
    "vect = TfidfVectorizer(ngram_range=(1,2), use_idf=True)\n",
    "vect.fit(df.text_pt)\n",
    "text_vect = vect.transform(df.text_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treina com a proporção de 80% para treinamento e 20% para teste\n",
    "X_train_diag,X_test_diag,y_train_diag,y_test_diag = train_test_split(\n",
    "    text_vect, \n",
    "    df.sentiment,\n",
    "    test_size = 0.2, \n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testa com SVM Linear\n",
    "#### MELHOR COM 89,48% ####\n",
    "\n",
    "svm_linear_diag = LinearSVC(penalty='l1',dual=False,C=1.0, random_state =42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_linear_diag.fit(X_train_diag, y_train_diag)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = svm_linear_diag.predict(X_test_diag)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_diag, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excelente resultado !! Melhor F1 Score obtido até então. <b>Novo valor máximo = 89,48%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa com multinomialNB\n",
    "\n",
    "naive_multi_diag = MultinomialNB()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "naive_multi_diag.fit(X_train_diag,y_train_diag)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = naive_multi_diag.predict(X_test_diag)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_diag, average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muito bom resultado também. F1 Score = <b>88,39%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Com otimização através de GridSearch no classificador LinearSVC ####\n",
    "#### MELHOR 90,97% de f1 score #####\n",
    "\n",
    "parametros = {'penalty': ['l1', 'l2'],\n",
    "              'C': [1.0,2.0,4.0] }\n",
    "\n",
    "\n",
    "svm_linear_opt = GridSearchCV(svm_linear_diag, parametros, scoring='f1_weighted')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_linear_opt.fit(X_train_diag, y_train_diag)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Tempo de treinamento: \" + str(end - start) + \"s\")\n",
    "\n",
    "y_prediction = svm_linear_opt.predict(X_test_diag)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test_diag, average='weighted')\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o modelo otimizado pela otimização dos hiperparâmetros (GridSearchCV). <b>Obtemos o novo melhor máximo = 90,97%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste do melhor método com K-FOLD \n",
    "X_kfold = X_train_diag\n",
    "#Y_kfold = y_train.as_matrix()\n",
    "Y_kfold = y_train_diag.values\n",
    "    \n",
    "kf = StratifiedKFold(n_splits=40,random_state=42,shuffle=True)\n",
    "\n",
    "clf = svm_linear_opt\n",
    "\n",
    "\n",
    "best_model = None \n",
    "best_f1 = -1 \n",
    "\n",
    "for train_index, test_index in kf.split(X_kfold,Y_kfold):  \n",
    "    X_train_kfold, X_test_kfold = X_kfold[train_index], X_kfold[test_index]\n",
    "    y_train_kfold, y_test_kfold = Y_kfold[train_index], Y_kfold[test_index]\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train_kfold, y_train_kfold)\n",
    "    y_prediction = clf.predict(X_test_kfold)\n",
    "    f1 = f1_score(y_prediction, y_test_kfold, average='weighted')\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "       best_f1 = f1\n",
    "       best_model = deepcopy(clf)\n",
    "    print(\"f1 obtido em treinamento...\")    \n",
    "    print(f1)\n",
    "\n",
    "\n",
    "\n",
    "X_final_test = X_test_diag \n",
    "#Y_final_test = y_test_diag.as_matrix()\n",
    "Y_final_test = y_test_diag.values\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_final_test)\n",
    "\n",
    "print(\"F1 final com a amostra de teste....\")\n",
    "f1 = f1_score(y_pred,Y_final_test,average='weighted')\n",
    "\n",
    "print(\"F1 Score: \" + str(round(f1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Mesmo utilizando treinamento com a estratégia de K-FOLD não se conseguiu superar o modelo otimizado com divisão simples de amostras de treinamento e validação. Nesse último teste, obteve-se F1 Score = <b>90,96%</b>. Quase o mesmo valor obtido anteriormente, mas ainda assim inferior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "# Resultado Final \n",
    "\n",
    "# Melhor algoritmo: SVM - LinearSVC\n",
    "\n",
    "# Melhor estratégia: Vetorizar utilizando unigramas e bigramas e TF-IDF\n",
    "\n",
    "# Otimização: Tuning dos hiperparâmetros do modelo LinearSVC utilizando GridSearchCV\n",
    "\n",
    "# F1 Score final: 90,97%\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
